{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import get_files_counters\n",
    "\n",
    "from os import listdir\n",
    "from os.path import splitext\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data\\\\stevci\\\\\"\n",
    "folder_ring = \"data\\\\stevci_obvoznica\\\\\"\n",
    "use_external_weather = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_id = get_files_counters.get_ids(folder)\n",
    "id_location = {location_id[x]:x for x in location_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"STM\", \n",
    "           \"date\" ,\n",
    "           \"time\", \n",
    "           \"motorbike1\", \n",
    "           \"car1\", \n",
    "           \"bus1\", \n",
    "           \"LT1\", \n",
    "           \"ST1\", \n",
    "           \"TT1\", \n",
    "           \"TP1\", \n",
    "           \"TPP1\", \n",
    "           \"count1\", \n",
    "           \"motorbike2\", \n",
    "           \"car2\", \n",
    "           \"bus2\", \n",
    "           \"LT2\", \n",
    "           \"ST2\", \n",
    "           \"TT2\", \n",
    "           \"TP2\", \n",
    "           \"TPP2\", \n",
    "           \"count2\", \n",
    "           \"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "file = \"STEP_MOL_1001-156_2020_09_01__00_00-2020_09_30__23_50.S_U\"\n",
    "df = pd.read_csv(folder+file, \n",
    "                 encoding=\"cp1250\", \n",
    "                 skiprows=12,\n",
    "                 header=None, \n",
    "                 sep='\\s{3,}', \n",
    "                 engine='python', \n",
    "                 usecols=np.arange(len(columns)))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = location_id[\"Dunajska zel. podvoz > Center\"]\n",
    "del location_id[\"Dunajska zel. podvoz > Center\"]\n",
    "location_id[\"Dunajska zel. podvoz <obe smeri> Center\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1,name in enumerate(location_id):\n",
    "    files = get_files_counters.get_file_names(name, location_id, folder)      \n",
    "    \n",
    "    for i2,f in enumerate(files):\n",
    "        df22 = pd.read_csv(folder+f, encoding=\"cp1250\", skiprows=12,sep='\\s{1,}', header=None, engine='python', usecols=np.arange(len(columns)))\n",
    "        #df = pd.read_csv(folder+f, encoding=\"cp1250\", skiprows=11,sep='\\s{1,}', engine='python')\n",
    "        if len(df22.iloc[0,1])<8: # pri letaliÅ¡ki je oznaka 1063 Let in je treba en stolpec izpustiti\n",
    "            df22 = pd.read_csv(folder+f, encoding=\"cp1250\", skiprows=12,sep='\\s{1,}', header=None, engine='python', usecols=np.arange(len(columns)+1))\n",
    "            df22 = df22.drop(columns=df22.columns[1])    \n",
    "        \n",
    "        df22 = df22.dropna()\n",
    "        df22.columns = columns\n",
    "        if \"obe smeri\" not in name: \n",
    "            df22 = df22[['date', 'time', 'count']]\n",
    "        else:\n",
    "            df22 = df22[['date', 'time', 'count1', 'count2']]\n",
    "            \n",
    "        if i2 == 0:\n",
    "            df21 = df22\n",
    "        else:\n",
    "            df21 = pd.concat([df21, df22], ignore_index=True, sort=False)\n",
    "   \n",
    "    if \"obe smeri\" not in name:    \n",
    "        #df21.to_csv(folder+\"obdelano\\\\\"+name.replace(\">\",\"\").replace(\"<\",\"\")+\".csv\")\n",
    "        \n",
    "        df21['location'] = name\n",
    "        df21['counter_id'] = location_id[name]\n",
    "        df21['direction'] = 0\n",
    "        if i1 == 0:\n",
    "            df = df21\n",
    "        else:\n",
    "            df = pd.concat([df, df21], ignore_index=True, sort=False)\n",
    "    else:\n",
    "        name_smer1 = name.replace(\"<obe smeri>\",\"SMER 0\")\n",
    "        name_smer2 = name.replace(\"<obe smeri>\",\"SMER 1\")\n",
    "            \n",
    "        df_smer1 = df21[['date', 'time', 'count1']].copy()\n",
    "        df_smer2 = df21[['date', 'time', 'count2']].copy()\n",
    "        \n",
    "        df_smer1.columns = ['date', 'time', 'count']\n",
    "        df_smer2.columns = ['date', 'time', 'count']\n",
    "        \n",
    "        #df_smer1.to_csv(folder+\"obdelano\\\\\"+name_smer1+\".csv\")\n",
    "        #df_smer2.to_csv(folder+\"obdelano\\\\\"+name_smer2+\".csv\")\n",
    "    \n",
    "        df_smer1['location'] = name_smer1\n",
    "        df_smer1['counter_id'] = location_id[name]\n",
    "        df_smer1['direction'] = 0\n",
    "        \n",
    "        df_smer2['location'] = name_smer2\n",
    "        df_smer2['counter_id'] = location_id[name]\n",
    "        df_smer2['direction'] = 1\n",
    "                \n",
    "        if i1 == 0:\n",
    "            df = pd.concat([df_smer1, df_smer2], ignore_index=True, sort=False)\n",
    "        else:\n",
    "            df = pd.concat([df, df_smer1, df_smer2], ignore_index=True, sort=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From additional CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_additional = \"data\\\\stevci_dodatni\\\\\"\n",
    "l = listdir(folder_additional)\n",
    "\n",
    "name = l[0]\n",
    "\n",
    "file_name = folder_additional + name\n",
    "    \n",
    "f = open(file_name, encoding=\"cp1250\")\n",
    "f = f.readlines()\n",
    "label = f[2].split(\":\")[1].split(\"/\")[0].strip()\n",
    "cols = f[22].strip().split()\n",
    "\n",
    "location = label.split()[1:]\n",
    "counter_id = name.split(\"_\")[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_additional = \"data\\\\stevci_dodatni\\\\\"\n",
    "l = listdir(folder_additional)\n",
    "\n",
    "for i1,name in enumerate(l):\n",
    "    file_name = folder_additional + name\n",
    "    \n",
    "    f = open(file_name, encoding=\"cp1250\")\n",
    "    f = f.readlines()\n",
    "    label = f[2].split(\":\")[1].split(\"/\")[0].strip()\n",
    "    cols = f[22].strip().split()\n",
    "\n",
    "    location = label.split()[1:]\n",
    "    counter_id = name.split(\"_\")[0]\n",
    "    \n",
    "    df2 = pd.read_csv(file_name, encoding=\"cp1250\", skiprows=24,sep='\\s{1,}', header=None, engine='python', usecols=np.arange(len(cols)))\n",
    "    df2 =df2.iloc[:,[1,2,11,20,21]]\n",
    "    df2.columns = [\"date\", \"time\", \"count1\", \"count2\", \"count\"]\n",
    "    df2 = df2.dropna()\n",
    "    \n",
    "    if \"obe_smeri\" not in name:    \n",
    "        df2 = df2[['date', 'time', 'count']]\n",
    "        df2['location'] = location\n",
    "        df2['counter_id'] = counter_id\n",
    "        df2['direction'] = 0\n",
    "        df = pd.concat([df, df2], ignore_index=True, sort=False)\n",
    "    \n",
    "    else:\n",
    "        df2 = df2[['date', 'time', 'count1', 'count2']]\n",
    "        \n",
    "        name_smer1 = name + \" SMER 0\"\n",
    "        name_smer2 = name + \" SMER 1\"\n",
    "            \n",
    "        df_smer1 = df2[['date', 'time', 'count1']].copy()\n",
    "        df_smer2 = df2[['date', 'time', 'count2']].copy()\n",
    "        \n",
    "        df_smer1.columns = ['date', 'time', 'count']\n",
    "        df_smer2.columns = ['date', 'time', 'count']\n",
    "        \n",
    "        #df_smer1.to_csv(folder+\"obdelano\\\\\"+name_smer1+\".csv\")\n",
    "        #df_smer2.to_csv(folder+\"obdelano\\\\\"+name_smer2+\".csv\")\n",
    "    \n",
    "        df_smer1['location'] = name_smer1\n",
    "        df_smer1['counter_id'] = counter_id\n",
    "        df_smer1['direction'] = 0\n",
    "        \n",
    "        df_smer2['location'] = name_smer2\n",
    "        df_smer2['counter_id'] = counter_id\n",
    "        df_smer2['direction'] = 1\n",
    "                \n",
    "        df = pd.concat([df, df_smer1, df_smer2], ignore_index=True, sort=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"date\"]!=\"skupaj\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['date'].map(lambda x: \"20\"+x.split('.')[2]) + \"-\" + df['date'].map(lambda x: x.split('.')[1]) + \"-\" + df['date'].map(lambda x: x.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From xlsx files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = listdir(folder)\n",
    "excel_files = []\n",
    "for f in l:\n",
    "    if splitext(f)[1] == \".xlsx\":\n",
    "        excel_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in excel_files:\n",
    "    xls_file = pd.ExcelFile(folder+name)\n",
    "    df2 = xls_file.parse(xls_file.sheet_names[1], header=None, skiprows=12)\n",
    "    df2.columns = columns[1:]\n",
    "    df2 = df2.dropna()\n",
    "    \n",
    "    counter_id = name.split()[0]\n",
    "    if counter_id in id_location:\n",
    "        location = id_location[counter_id]\n",
    "    else:\n",
    "        location = \" \".join(name.split()[1:]).split(\"-\")[0].strip()\n",
    "        \n",
    "    \n",
    "    if \"obe smeri\" not in name: \n",
    "        df2 = df2[['date', 'time', 'count']]       \n",
    "        df2['location'] = location\n",
    "        df2['counter_id'] = counter_id\n",
    "        df2['direction'] = 0\n",
    "        \n",
    "        df2['date'] = df2['date'].map(lambda x: x.split(\".\")[2]+\"-\"+x.split(\".\")[1]+\"-\"+x.split(\".\")[0])\n",
    "        \n",
    "        df = pd.concat([df, df2], ignore_index=True, sort=False)\n",
    "    else:\n",
    "        df2 = df2[['date', 'time', 'count1', 'count2']]\n",
    "        \n",
    "        df_smer1 = df2[['date', 'time', 'count1']].copy()\n",
    "        df_smer2 = df2[['date', 'time', 'count2']].copy()\n",
    "        \n",
    "               \n",
    "        df_smer1.columns = ['date', 'time', 'count']\n",
    "        df_smer2.columns = ['date', 'time', 'count']\n",
    "        \n",
    "        if counter_id in id_location:\n",
    "            name_smer1 = location.replace(\"<obe smeri>\",\"SMER 0\")\n",
    "            name_smer2 = location.replace(\"<obe smeri>\",\"SMER 1\")\n",
    "        else:\n",
    "            name_smer1 = location.replace(\"(obe smeri)\",\"SMER 0\")\n",
    "            name_smer2 = location.replace(\"(obe smeri)\",\"SMER 1\")\n",
    "        \n",
    "        \n",
    "        df_smer1['location'] = name_smer1\n",
    "        df_smer1['counter_id'] = counter_id\n",
    "        df_smer1['direction'] = 0\n",
    "        \n",
    "        df_smer2['location'] = name_smer2\n",
    "        df_smer2['counter_id'] = counter_id\n",
    "        df_smer2['direction'] = 1\n",
    "        \n",
    "        df_smer1['date'] = df_smer1['date'].map(lambda x: x.split(\".\")[2]+\"-\"+x.split(\".\")[1]+\"-\"+x.split(\".\")[0])\n",
    "        df_smer2['date'] = df_smer2['date'].map(lambda x: x.split(\".\")[2]+\"-\"+x.split(\".\")[1]+\"-\"+x.split(\".\")[0])\n",
    "        \n",
    "        df = pd.concat([df,df_smer1, df_smer2], ignore_index=True, sort=False)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional filter - using `counter_ids.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=[]\n",
    "f = open(\"data\\\\stevci\\\\counter_ids.txt\", encoding=\"utf8\")\n",
    "for x in f:\n",
    "    x=x.strip()\n",
    "    s.extend(x.split(\";\"))\n",
    "f.close()\n",
    "print(s)\n",
    "df = df[df[\"counter_id\"].isin(s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"counter_id\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"counter_id_direction\"] = df[\"counter_id\"]\n",
    "df.loc[df[\"direction\"]==1, \"counter_id_direction\"] = df[\"counter_id\"]+\"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time\"] = df[\"time\"].map(lambda x:int(x.split(\":\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From highway (ring) counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df2 = pd.read_csv(folder_ring+\"ring_counters.csv\")\n",
    "df_description = df2[[\"title\", \"id\", \"stevci_lokacijaOpis\"]]\n",
    "df_description = df_description.drop_duplicates()\n",
    "df_description.to_excel(folder_ring+\"ring_counters_description.xlsx\", index=False)\n",
    "df_description.to_csv(folder_ring+\"ring_counters_description.csv\", index=False)\n",
    "df2 = df2[[\"title\", \"stevci_datum\", \"stevci_ura\", \"stevci_stev\"]]\n",
    "df2.columns = ['counter_id', 'date', 'time', 'count']\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge all lanes in the same direction and sum the counts within an hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df2['counter_id'] = df2['counter_id'].map(lambda x: x.replace(' (v)','').replace(' (p)','').replace(' (po)',''))\n",
    "df2 = df2.groupby([\"counter_id\", \"date\", \"time\"], as_index=False).sum()\n",
    "\n",
    "df2[\"counter_id_direction\"] = df2[\"counter_id\"]\n",
    "df2[\"location\"] = df2[\"counter_id\"]\n",
    "df2[\"direction\"] = 0\n",
    "\n",
    "df2['date'] = df2['date'].map(lambda x: x.split(\"/\")[2]+\"-\"+x.split(\"/\")[1]+\"-\"+x.split(\"/\")[0])\n",
    "df2['date'] = pd.to_datetime(df2['date'])\n",
    "\n",
    "df2 = df2[['date', 'time', 'count', 'location', 'counter_id', 'direction' ,'counter_id_direction']]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2['time'] = df2['time'].map(lambda t: round(float(t.split(\":\")[0]) + float(t.split(\":\")[0])/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2.groupby(['date', 'time', 'location', 'counter_id', 'direction' ,'counter_id_direction'], as_index=False).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df2[df2[\"counter_id\"]==\"HC-H3, LJ (S obvoznica) : LJ (CelovÅ¡ka - Dunajska)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat with other counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,df2], ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the counter locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data\\\\counter_locations.txt\", 'w', encoding=\"utf8\")\n",
    "l = list(set(zip(df[\"location\"], df[\"counter_id\"])))\n",
    "l.sort()\n",
    "for counter_loc_id in l:\n",
    "    print(counter_loc_id, file=f)\n",
    "f.close()\n",
    "\n",
    "#pd.DataFrame({'location':df.location.unique()}).to_excel(\"data\\\\counter_locations.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['date', 'time', 'counter_id_direction', 'count']]\n",
    "df.columns = ['date', 'time', 'counter_id', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['date'] = df['date'].map(lambda x: \"20\"+x.split('.')[2]) + \"-\" + df['date'].map(lambda x: x.split('.')[1]) + \"-\" + df['date'].map(lambda x: x.split('.')[0] if len(x) < 10 else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unify the ids of the counters with different ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the synonyms\n",
    "d = {}\n",
    "\n",
    "f = open(\"data\\\\counter_synonyms.txt\", encoding=\"utf8\")\n",
    "for l in f:\n",
    "    l = l.strip().split(\";\")\n",
    "    primary = l[0]\n",
    "    syns = l[1:]\n",
    "    d[primary] = syns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for primary, syns in d.items():\n",
    "    for syn in syns:\n",
    "        df.loc[df['counter_id']  == syn, 'counter_id'] = primary\n",
    "        df.loc[df['counter_id']  == syn+'-1', 'counter_id'] = primary+'-1'   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove potential duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['counter_id', 'date', 'time'], as_index=False).max()\n",
    "# zakaj tole meÄ ven 1016-140;1946-230; 1035-136"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = df.counter_id.unique()\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = pd.DataFrame(columns = df.columns)\n",
    "\n",
    "\n",
    "for c in cs:\n",
    "    df2 = df[df.counter_id == c]\n",
    "    \n",
    "    \n",
    "    m, s = np.mean(df2['count']), np.std(df2['count'])\n",
    "    idxs = np.logical_not(np.logical_or(df2['count'] > m + 3 * s, df2['count'] < m - 3 * s))\n",
    "    df2 = df2[idxs]\n",
    "    df_filtered = pd.concat([df_filtered,df2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['date'].dt.weekday\n",
    "df['workday'] = df['weekday'].map(lambda x: 1 if x < 5 else 0)\n",
    "df = df.drop(columns = \"weekday\")\n",
    "df['workday'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_datetime(df_weather['date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_external_weather:\n",
    "    df_weather = pd.read_csv(\"data\\\\google_data_filtered.csv\", encoding=\"utf8\")\n",
    "    df_weather = df_weather[[\"date\", \"weather\"]]\n",
    "    df_weather = df_weather.drop_duplicates()\n",
    "    df_weather[\"date\"] = pd.to_datetime(df_weather['date'])\n",
    "    df = pd.merge(df, df_weather.drop_duplicates(), on=\"date\", how=\"left\")\n",
    "else:\n",
    "    df_weather = pd.read_csv('data\\\\weather.csv')\n",
    "    df_weather['date'] = pd.to_datetime(df_weather['date'])\n",
    "    for date in df['date'].unique():\n",
    "        try:\n",
    "            weather = df_weather.loc[df_weather['date'] == date, 'weather'].iloc[0]\n",
    "        except:\n",
    "            weather = np.nan\n",
    "        locs = date == df['date']\n",
    "        df.loc[locs, \"weather\"] = weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data\\\\counters.csv\", encoding=\"utf8\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.counter_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['weather'].isna()].date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbasecondacd385dda59854559b44e3f82ede14f15"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
